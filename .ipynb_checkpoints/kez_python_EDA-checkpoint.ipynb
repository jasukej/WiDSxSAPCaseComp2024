{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa303421-9581-4da1-8a0d-ce27b90cf29c",
   "metadata": {},
   "source": [
    "## **WiDSxSAP Case Competition 2024**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b6a41c-b35c-402f-8052-d8c6f790849e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b3d1d0-fd14-404f-a709-1676249b6c60",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6269086-8b38-48d4-a50b-16f361289d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9055c5c6-8756-46c1-9e51-ae1bcf2727fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the first few rows of the dataset\n",
    "print(train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9320f46f-c946-432b-bf68-97b7a9ace5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the total & types\n",
    "print(train.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf3d682-a982-47cc-a2f5-64d685caf8fc",
   "metadata": {},
   "source": [
    "We will run summary statistics and clean the data provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c2450f-2031-48f0-95af-39163e3da785",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics for numerical features\n",
    "print(train.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b4abc1-07ea-45ca-8e3f-4f4f1feca490",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count distinct values and mode for categorical features\n",
    "categorical_features = ['AI_Response_Time', 'Customer_Churn'] \n",
    "for feature in categorical_features:\n",
    "    print(f\"\\nValue counts for {feature}:\")\n",
    "    print(train[feature].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5631bce6-285d-49e5-bd1c-3d8579ed998b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify any missing values in the dataset\n",
    "print(train.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e5e683-7fd9-4d4b-96e8-3f012aef2e1d",
   "metadata": {},
   "source": [
    "The dataset is tidy, **equally distributed** between categories, and has **no null values**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f229908f-6d43-45a4-8202-6cc331f6a0d2",
   "metadata": {},
   "source": [
    "#### **Univariate Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a53792-dac8-4d8c-9971-c2beb981a9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the distribution of numerical features\n",
    "numerical_features = ['Age', 'Overall_Usage_Frequency'] \n",
    "for feature in numerical_features:\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    sns.histplot(train[feature], kde=True, bins=30)\n",
    "    plt.title(f'Distribution of {feature}')\n",
    "    plt.show()\n",
    "    \n",
    "# Separate histogram for Customer_Service_Interactions\n",
    "plt.figure(figsize=(5, 5))\n",
    "sns.histplot(data=train, x='Customer_Service_Interactions', binwidth=1)\n",
    "plt.title('Distribution of Customer Service Interactions')\n",
    "plt.xlabel('Customer Service Interactions')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23903571-d19b-40f2-864f-053948766149",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target variable\n",
    "plt.figure(figsize=(4,4))\n",
    "sns.countplot(x='Customer_Churn', data=train)\n",
    "plt.title('Distribution of Customer Churn')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ec4c9b-0f3b-40f6-9bea-fa21ba66be37",
   "metadata": {},
   "source": [
    "The data across different variables, both categorical and numerical, are distributed pretty evenly. However, as the target variable has more samples of positive customer churn, we will need to upsample our data during training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb360f4f-d152-461e-9d2c-7c1d231224ea",
   "metadata": {},
   "source": [
    "#### **Correlation Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f2cfaa-4a82-466f-b693-a9da4b6245c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting correlation matrix\n",
    "correlation_matrix = train.corr()\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Drawing heatmap\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt=\".2f\", cmap='coolwarm',\n",
    "            xticklabels=correlation_matrix.columns,\n",
    "            yticklabels=correlation_matrix.columns)\n",
    "plt.title(\"Correlation between variables of training set\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dcb894f-7af5-4361-82ca-f4aea45c1d0f",
   "metadata": {},
   "source": [
    "* AI interaction levels have a weak negative correlation (about 0.2) to customer churn.\n",
    "* Similarly, weak negative relationships can be observed related to Satisfaction with AI services and AI Personalization Effectiveness. \n",
    "* Conversely, Age has a weak but noticable positive correlation to customer churn."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b866742a-5d41-4cb6-a1e8-33229e481d90",
   "metadata": {},
   "source": [
    "#### **Analysing Bivariate Feature Relationships**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92bc88cf-8ae8-4bd3-89a2-a48a47d7fc08",
   "metadata": {},
   "source": [
    "We use box plots / scatter plots to visualize our **continuous** variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f53435-477d-4e73-b95d-1e033d78fa70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of continuous variables\n",
    "continuous_vars = ['Age', 'Overall_Usage_Frequency']\n",
    "\n",
    "fig, axes = plt.subplots(1, len(continuous_vars), figsize=(9, 5)) \n",
    "\n",
    "# Iterate through the variables and create a box plot for each\n",
    "for ax, column in zip(axes, continuous_vars):\n",
    "    sns.boxplot(ax=ax, x='Customer_Churn', y=column, data=train)\n",
    "    ax.set_title(f'{column} vs Customer Churn')\n",
    "    ax.set_xlabel('')  \n",
    "    ax.set_ylabel('')  \n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd48949c-419f-403c-ae1e-b7d82c565e41",
   "metadata": {},
   "source": [
    "We use stacked bar charts to visualize our **categorical** features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7512ae26-779a-4c2a-a013-cc7eb5e335eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the 'Customer_Churn' back to a categorical type for visualization\n",
    "train_df['Customer_Churn'] = train_df['Customer_Churn'].astype('category')\n",
    "\n",
    "# List of categorical variables\n",
    "categorical_vars = ['AI_Interaction_Level', 'Satisfaction_with_AI_Services', 'AI_Response_Time', 'Change_in_Usage_Patterns', 'AI_Personalization_Effectiveness']\n",
    "\n",
    "# Iterate through the list and create a stacked bar chart \n",
    "for var in categorical_vars:\n",
    "    cross_tab = pd.crosstab(index=train_df[var], columns=train_df['Customer_Churn'], normalize='index')\n",
    "    ax = cross_tab.plot(kind='bar', stacked=True, figsize=(10, 6))\n",
    "    plt.title(f'{var} vs Customer Churn')\n",
    "    plt.ylabel('Percentage')\n",
    "    for c in ax.containers:\n",
    "        ax.bar_label(c, fmt='%.2f%%', label_type='center')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e05237e-c857-4c65-b1d9-84e65899da99",
   "metadata": {},
   "source": [
    "#### **Feature Engineering**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c206a01b-65a9-408a-bea6-29333560da79",
   "metadata": {},
   "source": [
    "Based on the above insights, we will create a new feature for predicting churn: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c28c8ac-fb88-4e23-9070-1735b340a0dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8d342f7b-993b-4a08-bb3c-c48359f2bc95",
   "metadata": {},
   "source": [
    "## **Data Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8094802e-1246-480b-a012-2f92a1c1447d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dependencies\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler, MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2fb3f2d-93c2-4de8-bacf-3eb603314aa9",
   "metadata": {},
   "source": [
    "We will apply One-Hot Encoding to categorical variables to process them into a form that is better suited for prediction through machine learning algorithms. We create a binary column for each category in the original data variable and assign binary values accordingly (0, 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874f829a-ac1e-4cb4-9703-6304352182bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing OneHotEncoder\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "\n",
    "train_p = train\n",
    "\n",
    "# Apply One-Hot Encoding\n",
    "AI_Response_Time_encoded = onehot_encoder.fit_transform(train[['AI_Response_Time']])\n",
    "\n",
    "# List of categorical variables (Unsure of which is categorical yet?)\n",
    "categorical_vars = ['AI_Interaction_Level', 'AI_Response_Time']\n",
    "\n",
    "# Apply One-Hot Encoding\n",
    "for var in categorical_vars:\n",
    "    encoded_data = onehot_encoder.fit_transform(train[[var]])\n",
    "    encoded_df = pd.DataFrame(encoded_data, \n",
    "                              columns=[f\"{var}_{int(i)}\" for i in range(encoded_data.shape[1])])\n",
    "    \n",
    "    # Concatenate the new DataFrame to the original one\n",
    "    train_p = pd.concat([train_p.reset_index(drop=True), encoded_df.reset_index(drop=True)], axis=1)\n",
    "    \n",
    "    # Drop the original column\n",
    "    train_p.drop(var, axis=1, inplace=True)\n",
    "\n",
    "# Other variables are treated as numeric\n",
    "numeric_vars = ['Satisfaction_with_AI_Services', 'AI_Personalization_Effectiveness', 'Overall_Usage_Frequency', 'Customer_Service_Interactions', 'Change_in_Usage_Patterns']\n",
    "train_p[numeric_vars] = train_p[numeric_vars].apply(train_p.to_numeric)\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c271b799-49f5-4960-80c9-d9eaa3fe4ea6",
   "metadata": {},
   "source": [
    "#### **Scaling Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dccb483-4132-49df-8684-679bb6c089bf",
   "metadata": {},
   "source": [
    "Since we are looking to try different algorithms for prediction, we will perform standardization and normalization separately on the data to apply to different models accordingly. SVM and Logistic Regression models tend to benefit from standardization, while RNN models benefit more from normalization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee372df-edb4-4bde-b848-851c7109156f",
   "metadata": {},
   "source": [
    "#### **Standardizing the Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b352a36-d9c0-434b-bbcb-941df2c0bb1e",
   "metadata": {},
   "source": [
    "Result dataframe: train_p_standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eefcb650-53f7-4b92-9b8b-f75cfb982cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "train_p_standard = train_p\n",
    "\n",
    "# Apply standardization\n",
    "train_p_standard['Age'] = scaler.fit_transform(train_p_standard[['Age']])\n",
    "train_p_standard['Overall_Usage_Frequency'] = scaler.fit_transform(train_p_standard[['Overall_Usage_Frequency']])\n",
    "train_p_standard['Customer_Service_Interactions'] = scaler.fit_transform(train_p_standard[['Customer_Service_Interactions']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99be1f3e-b7ac-4dcd-b8ee-b59cf740b1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_p_standard.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03aa4f34-a507-44ea-a8d6-1ad894f971c6",
   "metadata": {},
   "source": [
    "#### **Data Normalization**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0355fe-02d2-4966-9392-0081553ec5d2",
   "metadata": {},
   "source": [
    "Result dataframe: train_p_normal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0081a01a-588e-4db4-89e7-a36809451e39",
   "metadata": {},
   "source": [
    "We do not need to conduct train-test splitting; the training and testing data has already been split."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e95e37-f67e-4ae8-ab70-19b6c87aca75",
   "metadata": {},
   "source": [
    "## **Model Selection**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e175e98-8edd-4be1-9576-c7e1ccca7441",
   "metadata": {},
   "source": [
    "#### **Baseline Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b167fb8-8b83-4d9f-9c1c-bfdac85c472f",
   "metadata": {},
   "source": [
    "We will use **Logistic Regression** as a commonly-implemented model for binary classification to establish baseline performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241d65ae-7627-49c0-a296-3c4b931fd1f5",
   "metadata": {},
   "source": [
    "#### **Model Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc861145-58a2-462d-b60c-f904ecb95912",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
